\section{KT Estimator and Its Applications}
\label{section:kt-estimator}

In this section we show that the potentials associated with Krichevsky-Trofimov
(KT) estimator form a sequence of excellent coin-betting potentials. We then
prove corollaries of the regret bounds for OLO in Hilbert space and learning
with expert advice that we proved in previous sections.

Given a sequence of coin flips $g_1, g_2, \dots, g_{t-1} \in \{+1,1\}$
the KT estimator is
\begin{equation}
\label{equation:kt-estimator}
\beta_t = \frac{\sum_{i=1}^{t-1} g_i}{t} \; .
\end{equation}
More commonly, KT estimator is expressed for a sequence of bits $b_1, b_2,
\dots, b_{t-1} \in \{0,1\}$ as $k_t = \frac{\frac{1}{2} + \sum_{i=1}^{t-1}
b_t}{t}$ and it is used in information theory as an estimator
of the probability of the next bit $b_i$ being $1$. Equation
\eqref{equation:kt-estimator} follows via linear transformation $g_t = 2b_t - 1$
and hence $\beta_t = 2k_t - 1$.

The coin-betting potential corresponding to KT estimator $\beta_t$ is
\begin{equation}
\label{equation:kt-estimator-potential}
F_t(x) = \epsilon \frac{2^t \Gamma(\frac{t+1}{2} + \frac{x}{2}) \Gamma(\frac{t+1}{2} - \frac{x}{2})}{\pi \cdot t!} \; ,
\end{equation}
where $\Gamma(x) = ï¿¼\int_0^\infty t^{-x} e^{-t} dt$ is Euler's gamma function.
The potential is defined on the interval $I_t = (-\frac{t+1}{2},
\frac{t+1}{2})$. Theorem~\ref{theorem:kt-potential} stated in the Appendix shows
that $\{F_t\}_{t=0}^\infty$ is a sequence of coin-betting potentials for initial
endownment $\epsilon$. It also shows that KT estimator, $\beta_t$, as defined by
\eqref{equation:kt-estimator}, is a potential-based strategy, i.e., it satisfies
\eqref{equation:potential-based-strategy}.

\subsection{OLO in Hilbert Space}

\begin{algorithm}[t]
\caption{Algorithm for OLO over Hilbert space $\H$ based on KT potential
\label{algorithm:kt-hilbert-space-olo}}
\begin{algorithmic}
{
\REQUIRE{Initial endowment $\epsilon > 0$}
\STATE{Initialize $\Wealth_0 \leftarrow \epsilon$}
\FOR{$t=1,2,\dots$}
\STATE{Set $w_t \leftarrow \frac{1}{t} \Wealth_{t-1} \sum_{i=1}^{t-1} g_i$}
\STATE{Predict $w_t$}
\STATE{Receive reward vector $g_t \in \H$ such that $\|g_t\| \le 1$}
\STATE{Update $\Wealth_t \leftarrow \Wealth_{t-1} \ + \ \langle g_t, w_t \rangle$}
\ENDFOR
}
\end{algorithmic}
\end{algorithm}

We apply KT potential for construction of an OLO algorithm in a Hilbert
space $\H$. According to \eqref{equation:hilbert-space-olo}, the resulting algorithm predicts
in round $t$,
$$
w_t = \beta_t \Wealth_{t-1} \frac{\sum_{i=1}^{t-1} g_i}{\norm{\sum_{i=1}^{t-1} g_i}}
$$
where $\beta_t$ is defined by
\eqref{equation:potential-based-strategy-hilbert-space}. According to
Theorem~\ref{theorem:kt-potential}, the formula for $\beta_t$ simplifies to
$\beta_t = \frac{\norm{\sum_{i=1}^{t-1} g_i}}{t}$. Hence, the prediction can be
written as
$$
w_t = \frac{1}{t} \Wealth_{t-1} \sum_{i=1}^{t-1} g_i \; .
$$
The algorithm is stated as Algorithm~\ref{algorithm:kt-hilbert-space-olo}.

We derive a regret bound for Algorithm~\ref{algorithm:kt-hilbert-space-olo} by
applying Theorem~\ref{theorem:hilbert-space-olo-regret-bound} to the KT
potential \eqref{equation:kt-estimator-potential}. The regret bound is stated as
Corollary~\ref{corollary:kt-hilbert-space-olo-regret} below. Its proof can be
found in the Appendix. The only technical part of the proof is an upper bound on
Fenchel conjugate $F_t^*$ since $F_t^*$ cannot be expressed as an elementary
function.

\begin{corollary}[Regret Bound for Algorithm~\ref{algorithm:kt-hilbert-space-olo}]
\label{corollary:kt-hilbert-space-olo-regret}
Let $\epsilon > 0$. Let $\{g_t\}_{t=1}^\infty$ be sequence of vectors in a
Hilbert space $\H$ such that $\norm{g_t} \le 1$.
Algorithm~\ref{algorithm:kt-hilbert-space-olo} satisfies
$$
\forall u \in H \qquad \qquad
\Regret_T(u) \le \norm{u} \sqrt{T \ln\left(1 + \frac{4T^2 \norm{u}^2}{\epsilon^2} \right)} + \epsilon \left(1 - \frac{1}{2\sqrt{T}} \right) \;.
$$
\end{corollary}

\subsection{Learning with Expert Advice}

\begin{algorithm}
\begin{algorithmic}
\caption{Algorithm for Learning with Expert Advice based on shifted KT potential
\label{algorithm:kt-experts}}
{
\REQUIRE{Number of experts $N$, number of rounds $T$, prior distribution $\pi \in \Delta_N$}
\FOR{$t=1,2,\dots,T$}
\STATE{For each $i \in [N]$, set $w_{t,i} \leftarrow \tfrac{\sum_{j=1}^{t-1} g_{j,i}}{t+T} \left(1 + \sum_{j=1}^{t-1} g_{j,i} w_{j,i} \right)$}
\STATE{For each $i \in [N]$, set $\widehat{p}_{t,i} \leftarrow \pi_i [w_{t,i}]_+$}
\STATE{Set $p_t \leftarrow
\begin{cases}
\hat{p}_t/\norm{\widehat{p}}_1 & \text{if $\norm{\widehat p}_1 > 0$} \\
\frac{1}{N}(1,1,\dots,1) & \text{if $\norm{\widehat p}_1 = 0$}
\end{cases}$}
\STATE{Predict $p_t$}
\STATE{Receive loss vector $\ell_t \in [0,1]^N$}
\STATE{For each $i \in [N]$, set $g_{t,i} \leftarrow \begin{cases}
\langle \ell_t, p_t \rangle - \ell_{t,i} & \text{if $w_{t,i} > 0$} \\
[\langle \ell_t, p_t \rangle - \ell_{t,i}]_+ & \text{if $w_{t,i} \le 0$}
\end{cases}$}
\ENDFOR
}
\end{algorithmic}
\end{algorithm}

We will construct an algorithm for Learning with Expert Advice based on
\emph{shifted KT potential}. The shifted potential and the resulting algorithm
requires to know the number of round $T$ in advance. The shifted potential is
defined as
$$
F_t(x) = \frac{2^t \cdot \Gamma(T + 1) \Gamma(\frac{t+T+1}{2} + \frac{x}{2}) \Gamma(\frac{t+T+1}{2} - \frac{x}{2})}{\Gamma(\frac{T+1}{2})^2 \cdot \Gamma(t+T+1)} \; .
$$
The reason for its name is that, up to a multiplicative constant, $F_t$ is equal
to the KT potential shifted in time by $T$, i.e., $t$ is replaced by $T+t$.
According to Theorem~\ref{theorem:kt-potential}, the shifted KT potentials form
a sequence of coin-betting potentials for initial endowment $1$. Futhermore, the
corresponding betting fraction is
$$
\beta_t = \frac{\sum_{j=1}^{t-1} g_j}{T+t} \; .
$$
Recall that for construction of the final algorithm, we need, as an intermediate
step, an OLO algorithm for one-dimensional Hilbert space $\R$. This algorithm
predicts for any sequence $\{g_t\}_{t=1}^\infty$ of reward vectors.
$$
w_t
= \beta_t \Wealth_{t-1}
= \beta_t \left(1 + \sum_{j=1}^{t-1} g_j w_j \right)
= \frac{\sum_{i=1}^{t-1} g_i}{T+t} \left(1 + \sum_{j=1}^{t-1} g_j w_j \right) \; .
$$
Following the construction in Section~\ref{section:reduction-experts}, we arrive
at the final algorithm, which we state as Algorithm~\ref{algorithm:kt-experts}.

We can derive a regret bound for Algorithm~\ref{algorithm:kt-experts} by
applying Theorem~\ref{theorem:regret-bound-experts} to the shifted KT potential.
The result is stated as Corollary~\ref{corollary:kt-experts-regret} below. The
proof of the corollary is in the Appendix. The hardest part of the proof is an
upper on $f_t^{-1}(x)$, which we conveniently do by lower bounding $F_t(x)$. The
reason for using the shifted potential comes from the analysis of $f_t^{-1}(x)$.
Unshifted algorithm would have $O(\sqrt{T (\log T + \KL{u}{\pi}})$ regret bound;
shifting improves the bound to $O(\sqrt{T (1 + \KL{u}{\pi}})$.

\begin{corollary}[Regret Bound for Algorithm~\ref{algorithm:kt-experts}]
\label{corollary:kt-experts-regret}
Let $N \ge 2$ and $T \ge 0$ be integers. Let $\pi \in \Delta_N$ be a prior.
For any sequence $\ell_1, \ell_2, \dots, \ell_T \in
[0,1]^N$ of loss vectors, Algorithm~\ref{algorithm:kt-experts}
with input $N,T,\pi$ satisfies,
$$
\forall u \in \Delta_N \qquad \qquad \Regret_T(u) \le \sqrt{3T (4 + \KL{u}{\pi})} \; .
$$
\end{corollary}

The requirement of knowing the number of rounds $T$ in advance can be lifted by
the standard doubling trick~\citep[Section 2.3.1]{Shalev-Shwartz12}. We obtain
an anytime algorithm at the expense of slighlty worse regret bound,
$$
\forall T \ge 0 \quad \forall u \in \Delta_N \qquad \qquad
\Regret_T(u) \le \frac{\sqrt{2}}{\sqrt{2} - 1} \sqrt{3T (4 + \KL{u}{\pi})} \; .
$$
