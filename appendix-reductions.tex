\section{Proof of Lemma~\ref{lemma:recursion_hilbert}}
\label{section:hilbert-space-reduction}

First we state the following Lemma from~\cite{McMahanO14} and reported here with our notation for completeness.
\begin{lemma}[Extremes]
\label{lemma:extremes}
Let $h:(-a,a) \to \R$ be an even convex twice-differentiable function that
satisfies $x \cdot h''(x) \ge h'(x)$ for all $x \in [0,a)$. Let $c \in \R$
be arbitrary. Then, if vectors $u,v \in \H$ satisfy $\|u\| + \|v\| < a$, then
\begin{equation}
\label{equation:lemma-extremes-1}
c \langle u, v \rangle - h(\|u + v\|) \ge \min \left\{ c \|u\| \cdot \|v\| - h(\|v\| + \|u\|), \ - c \|u\| \cdot \|v\| - h(\|u\| - \|v\|) \right\} \; .
\end{equation}
\end{lemma}
%
\begin{proof}
If $u$ or $v$ is zero, the inequality \eqref{equation:lemma-extremes-1} clearly
holds. From now on we assume that $u,v$ are non-zero. Let $\alpha$ be the cosine
of the angle of between $u$ and $v$. More formally,
$$
\alpha = \frac{\langle u, v \rangle}{\|u\| \cdot \|v\|} \; .
$$
With this notation, the left-hand side of \eqref{equation:lemma-extremes-1} is
$$
f(\alpha) = c \alpha \|u\| \cdot \|v\| - h(\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|}) \; .
$$
The inequality \eqref{equation:lemma-extremes-1} is equivalent to
$$
\forall \alpha \in [-1,1] \qquad \qquad f(\alpha) \ge \min \left\{f(+1), f(-1)\right\} \; .
$$
The last inequality is clearly true if $f:[-1,1] \to \R$ is concave. We now
check that $f$ is indeed concave, which we prove by showing that the second
derivative is non-positive. The first derivate of $f$ is
$$
f'(\alpha) = c \|u\| \cdot \|v\| - \frac{h'(\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|}) \cdot \|u\| \cdot \|v\|}{\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|}} \; .
$$
The second derivative of $f$ is
\begin{align*}
&f''(\alpha) = - \|u\|^2 \cdot \|v\|^2 \times \\
&\qquad \frac{h''(\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|})  - \frac{1}{\sqrt{\|u\|^2 + \|v\|^2 + 2\alpha \|u\| \cdot \|v\|}} \cdot h'(\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|})  }{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|} \; .
\end{align*}
If we consider $x = \sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|}$, the
assumption $x \cdot h''(x) \ge h'(x)$ implies that $f''(\alpha)$ is non-positive.
This finishes the proof of the inequality \eqref{equation:lemma-extremes-1}.
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lemma:recursion_hilbert}]
Since $F_t(x)$ is an excellent coin-betting potential, is convex and satisfies $x
F_t''(x) \ge F_t'(x)$. Hence,
\begin{align*}
&\left(1 + \beta_t \frac{\langle g_t, x \rangle}{\|x\|} \right) F_{t-1}(\norm{x}) - F_t(\norm{x + g_t}) \\
&\quad = F_{t-1}(\norm{x}) + \beta_t \frac{\langle g_t, x \rangle}{\|x\|} F_{t-1}(\norm{x}) - F_t(\norm{x + g_t}) \\
&\quad \ge F_{t-1}(\norm{x})+\min_{r \in \{-1,1\}} \beta_t r \norm{g_t} F_{t-1}(\norm{x}) - F_t(\norm{x} + r \norm{g_t}) \\
&\quad =\min_{r \in \{-1,1\}} \left(1 + \beta_t r \norm{g_t}\right) F_{t-1}(\norm{x}) - F_t(\norm{x} + r \norm{g_t}) \\
&\quad \ge 0 \; .
\end{align*}
The first inequality comes from Lemma~\ref{lemma:extremes} with $h(z) = F_t(z)$,
$c = \beta_t F_{t-1}(\norm{x}) / \norm{x}$ and $u=g_t$ and $v=x$ unless $\norm{x} = 0$.
If $\norm{x}=0$ then $\beta_t = 0$ and the first inequality trivially holds.
The second inequality follows from the property 3 of a coin-betting potential.
\end{proof}
