\section{How to Tune the Learning Rates?}
\label{section:learning-rates}

Consider \ac{OLO} over a Hilbert Space $\H$. \ac{OGD} with learning rate
$\eta$ satisfies~\citep{Shalev-Shwartz-2011}
\begin{equation}
\label{equation:ftrl-vanila}
\forall u \in \H \qquad \Regret_T(u) \le \tfrac{\norm{u}^2}{2\eta} + \tfrac{\eta T}{2} \; .
\end{equation}
It is obvious that the optimal tuning of the learning rate depends on the
unknown norm of $u$.

The simple choice $\eta = 1/\sqrt{T}$ leads to an algorithm that satisfies
\begin{equation}
\label{equation:ftrl-vanila-2}
\forall u \in H \qquad \Regret_T(u) \le \tfrac{1}{2}\left(1+\norm{u}^2\right)\sqrt{T} \; .
\end{equation}
However, in this bound the dependency on $\norm{u}$ is suboptimal: The
quadratic dependency can be replaced by an (almost) linear dependency.
Starting from \eqref{equation:ftrl-vanila}, if we choose the learning rate
$\eta = D/\sqrt{T}$, we get a family of algorithms parametrized by $D \in
[0,\infty)$ that satisfy
\begin{equation}
\label{equation:ftrl-vanila-3}
\forall u \in \H : \norm{u} \le D \quad  \Longrightarrow \quad \Regret_T(u) \le D \sqrt{T} \; .
\end{equation}
Instead of a family of algorithms parametrized by $D \in [0,\infty)$ satisfying
the bound \eqref{equation:ftrl-vanila-3}, one \emph{would like
to have} a single algorithm (without any tuning parameters) satisfying
\begin{equation}
\label{equation:olo-parameter-free}
\forall u \in \H \qquad \Regret_T(u) \le \norm{u} \sqrt{T} \; .
\end{equation}
Notice that \eqref{equation:olo-parameter-free} is stronger than
\eqref{equation:ftrl-vanila-3} in the following sense: A single algorithm
satisfying \eqref{equation:olo-parameter-free} implies
\eqref{equation:ftrl-vanila-3} for all values of $D \in [0,\infty)$. However,
a family of algorithms $\{A_D : D \in [0,\infty)\}$ parametrized by $D$ where
$A_D$ satisfies \eqref{equation:ftrl-vanila-3}, does not yield a single
algorithm that satisfies \eqref{equation:olo-parameter-free}.  Finally, note
that \eqref{equation:olo-parameter-free} has better dependency on $\norm{u}$
than \eqref{equation:ftrl-vanila-2}.

However better guarantees are possible. In fact, there have been a lot of work on algorithms \citep{Streeter-McMahan-2012,
Orabona-2013, McMahan-Abernethy-2013,
McMahan-Orabona-2014,Orabona-2014} that satisfy a slightly
weaker version of \eqref{equation:olo-parameter-free}. Namely, their regret satisfies
\begin{equation}
\label{equation:olo-parameter-free-2}
\forall u \in \H \qquad \Regret_T(u) \le \big(O(1)+\polylog(1 + \norm{u})\norm{u} \big) \sqrt{T} \; .
\end{equation}
It can be shown that for \ac{OLO} over Hilbert space the extra poly-logarithmic
factor is necessary~\citep{McMahan-Abernethy-2013,Orabona-2013}. Algorithms
satisfying \eqref{equation:olo-parameter-free-2} are called
\emph{parameter-free}, since they do not need to know $D$, yet they have an
optimal dependency on $\norm{u}$.
