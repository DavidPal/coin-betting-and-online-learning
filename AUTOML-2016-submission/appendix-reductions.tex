\section{Proof of Lemma~\ref{lemma:recursion_hilbert}}
\label{section:hilbert-space-reduction}

First we state the following Lemma from~\cite{McMahan-Orabona-2014} and reported here with
our notation for completeness.

\begin{lemma}[Extremes]
\label{lemma:extremes}
Let $h:(-a,a) \to \R$ be a twice-differentiable function that
satisfies $x \cdot h''(x) \ge h'(x)$ for all $x \in [0,a)$. Let $c:[0,\infty) \to \R$
be an arbitrary function. Then, if vectors $u,v \in \H$ satisfy $\|u\| + \|v\| < a$, then
\begin{multline}
\label{equation:lemma-extremes-1}
c(\norm{u}, \norm{v}) \cdot \langle u, v \rangle - h(\norm{u+v})
\ge \min \left\{ c(\norm{u}, \norm{v}) \cdot \norm{u} \cdot \norm{v} - h(\norm{v} + \norm{v}), \right. \\
\left. - c(\norm{u}, \norm{v}) \cdot \norm{u} \cdot \norm{v} - h(\norm{u} - \norm{v}) \right\} \; .
\end{multline}
\end{lemma}
%
\begin{proof}
If $u$ or $v$ is zero, the inequality \eqref{equation:lemma-extremes-1} clearly
holds. From now on we assume that $u,v$ are non-zero. Let $\alpha$ be the cosine
of the angle of between $u$ and $v$. More formally,
$$
\alpha = \frac{\langle u, v \rangle}{\norm{u} \cdot \norm{v}} \; .
$$
With this notation, the left-hand side of \eqref{equation:lemma-extremes-1} is
$$
f(\alpha) = c(\norm{u}, \norm{v}) \cdot \alpha \norm{u} \cdot \norm{v} - h(\sqrt{\norm{u}^2 + \norm{v}^2 + 2 \alpha \norm{u} \cdot \norm{v}}) \; .
$$
Since $h$ is even, the inequality \eqref{equation:lemma-extremes-1} is equivalent to
$$
\forall \alpha \in [-1,1] \qquad \qquad f(\alpha) \ge \min \left\{f(+1), f(-1)\right\} \; .
$$
The last inequality is clearly true if $f:[-1,1] \to \R$ is concave. We now
check that $f$ is indeed concave, which we prove by showing that the second
derivative is non-positive. The first derivative of $f$ is
$$
f'(\alpha) = c(\norm{u}, \norm{v}) \cdot \|u\| \cdot \|v\| - \frac{h'(\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|}) \cdot \|u\| \cdot \|v\|}{\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|}} \; .
$$
The second derivative of $f$ is
\begin{multline*}
f''(\alpha) = - \frac{\|u\|^2 \cdot \|v\|^2}{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|} \\
 \cdot \left( h''(\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|})  - \frac{h'(\sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|})}{\sqrt{\|u\|^2 + \|v\|^2 + 2\alpha \|u\| \cdot \|v\|}}  \right) \; .
\end{multline*}
If we consider $x = \sqrt{\|u\|^2 + \|v\|^2 + 2 \alpha \|u\| \cdot \|v\|}$, the
assumption $x \cdot h''(x) \ge h'(x)$ implies that $f''(\alpha)$ is non-positive.
This finishes the proof of the inequality \eqref{equation:lemma-extremes-1}.
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lemma:recursion_hilbert}]
Since $F_t(x)$ is an excellent coin-betting potential, it satisfies $x
F_t''(x) \ge F_t'(x)$. Hence,
\begin{align*}
&\left(1 + \beta_t \frac{\langle g_t, x \rangle}{\norm{x}} \right) F_{t-1}(\norm{x}) - F_t(\norm{x + g_t}) \\
&\quad = F_{t-1}(\norm{x}) + \beta_t \frac{\langle g_t, x \rangle}{\norm{x}} F_{t-1}(\norm{x}) - F_t(\norm{x + g_t}) \\
&\quad \ge F_{t-1}(\norm{x})+\min_{r \in \{-1,1\}} \beta_t r \norm{g_t} F_{t-1}(\norm{x}) - F_t(\norm{x} + r \norm{g_t}) \\
&\quad =\min_{r \in \{-1,1\}} \left(1 + \beta_t r \norm{g_t}\right) F_{t-1}(\norm{x}) - F_t(\norm{x} + r \norm{g_t}) \\
&\quad \ge 0 \; .
\end{align*}
If $x \neq 0$, the first inequality comes from Lemma~\ref{lemma:extremes} with
$c(z,\cdot) = \frac{F_{t-1}(z+1) - F_{t-1}(z-1)}{F_{t-1}(z+1) + F_{t-1}(z-1)} F_{t-1}(z) / z$ and
$h(z) = F_t(z)$, $u=g_t$, $v=x$.
If $x=0$ then, according to
\eqref{equation:potential-based-strategy-hilbert-space}, $\beta_t = 0$ and the
first inequality trivially holds. The second inequality follows from the
property 3 of a coin-betting potential.
\end{proof}
