\documentclass[final,t,serif,mathserif]{beamer}

\usefonttheme{serif}
\setbeamertemplate{items}[circle]
\usepackage{pxfonts}
\usepackage{mathpazo}
% \usepackage{times}


\mode<presentation>
{
  \usetheme{I6pd}
  \usefonttheme{professionalfonts}
}

% additional settings
\setbeamerfont{itemize}{size=\normalsize}
\setbeamerfont{itemize/enumerate body}{size=\normalsize}
\setbeamerfont{itemize/enumerate subbody}{size=\normalsize}

%\setbeamertemplate{bibliography item}[text]

% additional packages
\usepackage{amsfonts}
\usepackage{amsmath, amssymb}
\usepackage{amsthm}
\usepackage{exscale}
\usepackage{algorithmic}
\usepackage{multicol}
%\boldmath
\usepackage{booktabs, array}
%\usepackage{rotating} %sideways environment
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
%\usepackage[orientation=landscape,size=a0,scale=1.3]{beamerposter}
\usepackage[orientation=landscape,size=custom,width=121,height=91,scale=1.47]{beamerposter}
%\usepackage[orientation=portrait,size=a4,scale=1.3]{beamerposter}
\listfiles
\usepackage{multicol}
\usepackage{enumitem}

\input{symbol_poster.tex}

\DeclareMathOperator*{\Exp}{\mathbf{E}}
\DeclareMathOperator{\Wealth}{Wealth}
\newcommand{\grad}{\nabla}
\renewcommand{\H}{\mathcal{H}}  % Hilbert space
\DeclareMathOperator{\Regret}{Regret}
\DeclareMathOperator{\polylog}{polylog}
\DeclareMathOperator{\Reward}{Reward}

\title{\huge Parameter-Free Convex Learning through Coin Betting}
\author{Francesco Orabona \and D\'avid P\'al}
\institute[] % (optional, but mostly needed)
{
  Yahoo Research, New York
}
\date[June 24, 2016]{June 24, 2016}

% abbreviations
\usepackage{xspace}
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\def\eg{{e.g}\onedot} \def\Eg{{E.g}\onedot}
\def\ie{{i.e}\onedot} \def\Ie{{I.e}\onedot}
\def\cf{{c.f}\onedot} \def\Cf{{C.f}\onedot}
\def\etc{{etc}\onedot}
\def\vs{{vs}\onedot}
\def\wrt{w.r.t\onedot}
\def\dof{d.o.f\onedot}
\def\etal{{et al}\onedot}
\makeatother

\def\spazioBlocchi{\vspace{0cm}}
\def\blockspacea{\vspace{0.cm}}
\def\blockspaceb{\vspace{0.08cm}}
\def\blockspacec{\vspace{0.25cm}}

\setitemize{label=\usebeamerfont*{itemize item}%
  \usebeamercolor[fg]{itemize item}
  \usebeamertemplate{itemize item}}
\setlist{leftmargin=*,labelindent=0cm,labelsep=1cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\begin{frame}{}

\begin{columns}[t]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{column}{.33\linewidth}

    \begin{block}{ARE YOU STILL TUNING HYPERPARAMETERS?}
      \blockspacea
      
      Regularized empirical risk minimization:
      \begin{equation}
      \label{equation:objective-function}
         \argmin_{w \in \R^d} \ \frac{\lambda}{2} \norm{w}^2 + \sum_{i=1}^N f(w, x_i, y_i)
      \end{equation}
      where $f$ is convex in $w$.
      \begin{itemize}
      \item How do you choose the learning rate $\lambda$?
      \end{itemize}
      
      \vspace{1cm}
      
      Stochastic approximation:
      \begin{equation}
      \label{equation:objective-function-sa}
         w_t = w_{t-1} - \eta_t \grad f(w_{t-1}, x_t, y_t)
      \end{equation}
      where $f$ is convex in $w$.
      \begin{itemize}
      \item How do you choose the learning rate $\eta_t$?
      \end{itemize}
      
      \vspace{1cm}
      
      \begin{itemize}      
      \item \alert{Why is the algorithm not able to select $\lambda$ and learning rate automatically?}
      \end{itemize}
      
      \blockspacea
    \end{block}

    \begin{block}{FROM COIN-BETTING TO MACHINE LEARNING}
    \blockspacea
    
    \begin{itemize}
      \item Problem~\eqref{equation:objective-function} can be solved with an Online Linear Learning algorithm.
      \item We prove that Online Linear Learning can be solved with online coin-betting algorithms.
    \end{itemize}

    \vspace{1cm}

    \begin{itemize}
      \item Coin flip outcome $c_t \in \{+1, -1\}$.
      \item Krichevsky-Trofimov: Bet $\tfrac{1}{t} \sum_{i=1}^{t-1} c_i$ fraction of your current wealth on the most common outcome till time $t$
      \item \alert{KT algorithm for coin betting gives rise to optimal parameter-free algorithms for Online Learning, Convex Optimization and Machine Learning!}
      \item Key idea: Treat the gradient as the outcome of a coin flip.
      \item In other words: \alert{Learning rates are the results of suboptimal algorithms, they must be removed, not tuned/learned/adapted!}
    \end{itemize}
    
    \blockspacea
    \end{block}

    \begin{block}{THE HISTORY OF PARAMETER-FREE ALGORITHMS}
    \blockspacea
    
    \begin{itemize}
    \item Streeter\&McMahan (2012): Regret in $\R^1$ that depends on $|u| \log|u|$ instead of $|u|^2$.
    \item Orabona (2013): Generalization to Hilbert space.
    \item McMahan\&Orabona (2014): Upper and lower bound $\norm{\bu} \sqrt{\log(\norm{\bu}+1)}$.
    \item Orabona (2014): Link between new online algorithms and self-tuning SVMs, and a data dependent bound.
    \item A parallel line of work on adaptive learning with expert advice: Chaudhuri et al. (2009), Chernov\&Vovk (2010), Luo\&Schapire (2014, 2015), Koolen\&van-Erven (2015), Foster et al. (2015).
    \item Orabona\&P\'al (2016): Adaptive algorithms for Online linear learning and learning with expert advices can be easily obtained from algorithms for coin-betting.
    \end{itemize}

%     \begin{block}{BIBLIOGRAPHY}
%     %\vspace{-1cm}
%     %\begin{multicols}{2}
%     \tiny
%     Streeter and McMahan. No-regret algorithms for unconstrained online convex optimization. NIPS 2012.\\
%     Orabona. Dimension-free exponentiated gradient. NIPS 2013.\\
%     McMahan and Orabona. Unconstrained online linear learning in Hilbert spaces: Minimax algorithms and normal approximations. COLT 2014.\\
%     Orabona and Pal. From Coin Betting to Parameter-Free Online Learning. ArXiv 2016.
%     %\end{multicols}
%     %\vspace{-1cm}
%     \end{block}
%     \end{minipage}
    \blockspacea
    \end{block}


\end{column}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{column}{.33\linewidth}

    \begin{block}{PARAMETER-FREE SGD BASED ON THE KT ESTIMATOR}
	\blockspaceb
	
	\begin{algorithmic}[1]
	{
	\REQUIRE{Convex functions $f_1, f_2, \dots, f_N$ and desired number of iterations $T$}
	\STATE{Initialize $\Wealth_0 \leftarrow 1$ and $\theta_0 \leftarrow 0$}
	\FOR{$t=1,2,\dots,T$}
	\STATE{Set $w_t \leftarrow \Wealth_{t-1} \tfrac{\theta_{t-1}}{t} $}
	\STATE{Select an index $j$ at random from $\{1,2,\dots,N\}$}
	\STATE{Update $\theta_t \leftarrow \theta_{t-1} - \grad f(w_{t-1},x_j,y_j)$}
	\STATE{$\Wealth_t \leftarrow \Wealth_{t-1} - \langle \grad f(w_{t-1},x_j,y_j), w_t \rangle$}
	\ENDFOR
	\STATE{Output $\overline{w}_T = \tfrac{1}{T}\sum_{t=1}^T w_t$}
	}
	\end{algorithmic}

	\blockspaceb
    \end{block}


    \begin{block}{THEORETICAL GUARANTEES}
	\blockspaceb
	
	\textbf{One epoch: $T\leq N$}
	
	The average $\overline{w}_T$ is an approximate minimizer of the risk $\Exp[f(w,X,Y)]$:
	\[
	\Exp\left[F(\overline{w}_T,X,Y)\right] - F(w^*,X,Y) \leq \tfrac{\norm{w^*}}{\sqrt{T}} \sqrt{\log(1+4 T^2 \norm{w^*}^2)} +\tfrac{1}{T} \; .
	\]
	
	\vspace{1cm}
	
	\textbf{Multiple epochs: $T>N$}
	
	The average $\overline{w}_T$ is an approximate minimizer of training set error $F(w) = \sum_{i=1}^N f(w,x_i,y_i)$:
	\[
	\Exp\left[F(\overline{w}_T)\right] - F(\widehat{w}) \leq \tfrac{\norm{\widehat{w}}}{\sqrt{T}} \sqrt{\log(1+4 T^2 \norm{\widehat{w}}^2)} +\tfrac{1}{T} \; .
	\]
	
	\blockspaceb	
    \end{block}

    \begin{block}{DOES IT WORK FOR REAL?}
      \blockspaceb
      
      \begin{itemize}
        \item Split data into 75\% training + 25\% test
        \item Train with one pass over the training set and evaluate the final classifier on the test set.
        \item Use 5 different splits into training+test. Report average and standard deviation.
        \item We have run SGD with different learning rates and shown the performance of its last solution on the test set.
       \end{itemize}
      \begin{figure}[t]
	\centering
	\begin{tabular}{ccc}
	\includegraphics[width=0.3\textwidth]{../figs/yearPredictionMSD_kt_train_test-crop.pdf} &
        \includegraphics[width=0.3\textwidth]{../figs/cpusmall_kt_train_test-crop.pdf} &
        \includegraphics[width=0.3\textwidth]{../figs/cadata_kt_train_test-crop.pdf}
	\end{tabular}
      \end{figure}
      \begin{itemize}
        \item It is clear that the optimal learning rate is completely data-dependent.
        \item It is also interesting to note how the performance of SGD becomes very unstable with large learning rates. \item Yet \emph{our parameter-free algorithm has a performance very close to the unknown optimal tuning of the learning rate of SGD}.
       \end{itemize}
       
       \blockspaceb
       
    \end{block}
\end{column}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{column}{.33\linewidth}

    \begin{block}{TECHNICAL DETAILS}
    \begin{minipage}{.98\linewidth}

    \blockspacec
    
    Read only if you want the math details!
    
    \blockspacec

    \begin{block}{LEARNING RATES IN ONLINE LINEAR LEARNING}
    \blockspacec
    
    \begin{itemize}
      \item Define
      \[
        \Regret_T(u) = \sum_{t=1}^T \langle \ell_t, w_t \rangle - \sum_{t=1}^T \langle \ell_t, u \rangle  \; .
      \]
      \item OGD with learning rate $\eta$ satisfies
	\[
	\forall u \in \H \qquad \Regret_T(u) \le \tfrac{\norm{u}^2}{2\eta} + \tfrac{\eta}{2} \sum_{t=1}^T \norm{\ell_t}^2
	\]
      \item Optimal oracle choice: $\eta = \frac{\norm{u}}{\sqrt{\sum_{t=1}^T \norm{\ell_t}^2}}$.
      \item Tons of algorithms adapt to the norms of the gradients, e.g. AdaGrad
      \item Adapting to the unknown norm of $u$ is \emph{more difficult and more important}.
      \item Better guarantees are indeed possible: Streeter\&McMahan (2012), Orabona (2013), McMahan\&Abernethy (2013), McMahan\&Orabona (2014), Orabona (2014) 
	\[
	\forall u \in \H \qquad \Regret_T(u) \le \big(O(1)+\polylog(1 + \norm{u})\norm{u} \big) \sqrt{T} \; .
	\]
    \end{itemize}
    
    \blockspacec
    \end{block}

    \begin{block}{REGRET GUARANTEE}
    \blockspacec
    
    \alert{Theorem.} \emph{
	Let $\{\ell_t\}_{t=1}^\infty$ be any sequence of loss vectors
	in a Hilbert space $\H$ such that $\norm{\ell_t} \le 1$.
	The KT-based online algorithm satisfies
	$$
	\forall \, T \ge 0, \
	\forall u \in \H \quad
	\Regret_T(u) \le \norm{u} \sqrt{T \ln\left(1 + 4T^2 \norm{u}^2 \right)} + 1 \, .
	$$
    }

    \vspace{1cm}

    \alert{Proof Sketch.}
    \begin{itemize}
    \item Duality between wealth and regret: Let $F:\H \to \R$ be convex. For any $w_1, \dots, w_T$ and $g_1, \dots, g_T$,
    \[
      \underbrace{\sum_{t=1}^T \langle g_t, w_t \rangle}_{\Reward_T} \ge F\left( \sum_{t=1}^T g_t \right)
      \ \Leftrightarrow \
      \forall u \in \H, \
      \underbrace{\sum_{t=1}^T \langle g_t, u - w_t\rangle}_{\Regret_T(u)} \le F^*(u)
    \]
    \item Consider the $1$-dimensional case $\H=\R^1$.
    \item Set $w_t=\beta_t \Wealth_{t-1}$ where $\beta_t$ is the KT estimator.
    \item If $\ell_t \in \{+1, -1\}$, the results follows directly from the guarantee on the KT estimator and duality above.
    \item Extend to $\ell_t \in [-1,1]$ by convexity: The worst $\ell_t$ is always $+1$ or $-1$.
    \item Extend $1$-d case to Hilbert space: Worst direction is always parallel to the sum of the previous $\ell_t$.
    \end{itemize}
    \end{block}
    \end{minipage}
    \blockspacec
    \end{block}
\end{column}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{columns}
\end{frame}
\end{document}
