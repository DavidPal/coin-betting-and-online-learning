\section{Introduction}
\label{section:introduction}

We consider the \ac{OLO}~\citep{Cesa-Bianchi-Lugosi-2006, Shalev-Shwartz-2011}
over a Hilbert space $\H$. In each round $t$, an algorithm chooses a point $x_t
\in \H$ and then receives a reward vector $g_t \in \H$. The algorithm's goal is
to keep its \emph{regret} small, defined as the difference between its
cumulative reward and the cumulative reward of a fixed strategy $u \in \H$,
that is
\[
\Regret_T(u) = \sum_{t=1}^T \langle \ell_t, w_t \rangle - \sum_{t=1}^T \langle \ell_t, u \rangle \; .
\]
We focus on one particular decision set, the Hilbert space
$\H$. 
%\ac{OLO} over $\Delta_N$ is referred to as the problem of \ac{LEA}.
We assume bounds on the norms of the reward vectors: we
assume that $\norm{\ell_t} \le 1$.
%, and for \ac{LEA} we assume that $g_t \in [0,1]^N$.

\ac{OLO} is a basic building block of many machine learning problems. For
example, \ac{OCO}, the problem analogous to \ac{OLO} where $\langle \ell_t, u
\rangle$ is generalized to an arbitrary convex function $f_t(u)$, is solved
through a reduction to \ac{OLO}~\citep{Shalev-Shwartz-2011}.
%\ac{LEA}~\citep{Littlestone-Warmuth-1994, Vovk-1998, Cesa-Bianchi-Freund-Haussler-Helmbold-Schapire-Warmuth-1997} provides a way of combining classifiers and it is at the heart of boosting~\citep{Freund-Schapire-1997}.
Batch and stochastic convex optimization
can also be solved through a reduction to \ac{OLO}~\citep{Shalev-Shwartz-2011}.

To achieve optimal regret, most of the existing online algorithms (e.g.  Online
Gradient Descent) require the user to set the learning rate to an
unknown/oracle value. Recently, new parameter-free algorithms have been
proposed for \ac{OLO}/\ac{OCO} over Hilbert
spaces~\citep{Streeter-McMahan-2012, Orabona-2013, McMahan-Abernethy-2013,
McMahan-Orabona-2014, Orabona-2014}.  These algorithms adapt to the norm of the
optimal predictor, without the need to tune parameters. However, their
\emph{design and underlying intuition} is still a challenge.
%\citet{Foster-Rakhlin-Sridharan-2015} proposed a unified framework, but it is not constructive.
%Furthermore, all
%existing algorithms for LEA either have sub-optimal regret bound (e.g. extra
%$\scO(\log \log T)$ factor) or sub-optimal running time (e.g.  requiring
%solving a numerical problem in every round, or with extra factors).

Our contributions are as follows. We connect algorithms for \ac{OLO} with coin
betting. Namely, we show an algorithm for \ac{OLO} can be viewed as an
algorithm for betting on outcomes of adversarial coin flips. The wealth the
algorithm can generate for the betting problem is connected to the regret in
\ac{OLO} setting. This insight allows us to design novel parameter-free
algorithms, which are extremely simple and natural. We also show some
applications of our results to convex optimization and machine learning.

\noindent\textbf{Notation and Definitions.}
We will use the following notation in the rest of this note.  If $\H$ is a real
Hilbert space, $\langle \cdot, \cdot \rangle$ is its inner product and
$\norm{\cdot}$ its induced norm.
