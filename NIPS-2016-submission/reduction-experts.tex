\section{From Coin Betting to Learning with Expert Advice}
\label{section:reduction-experts}

In this section, we show how to use the algorithm for OLO over one-dimensional Hilbert space $\R$
from Section~\ref{section:one-dimensional-hilbert-space-olo}--which is itself
based on a coin-betting strategy---to construct an algorithm for \ac{LEA}.

Let $N \ge 2$ be the number of experts and $\Delta_N$ be the $N$-dimensional
probability simplex. Let $\pi = (\pi_1, \pi_2, \dots, \pi_N) \in \Delta_N$ be
any \emph{prior} distribution. Let $A$ be an algorithm for OLO over
one-dimensional Hilbert space $\R$. We instantiate $N$ copies of $A$.

Consider any round $t$. Let $w_{t,i} \in \R$ be the prediction of $i$-th copy of
$A$. The LEA algorithm computes $\widehat p_t = (\widehat p_{t,1}, \widehat
p_{t,2}, \dots, \widehat p_{t,N}) \in \R_{0,+}^N$,
\[
\widehat p_{t,i} = \pi_i \cdot [w_{t,i}]_+
\]
where $[x]_+ = \max\{0,x\}$ is the positive part of $x$. Then, the LEA
algorithm predicts $p_t = (p_{t,1}, p_{t,2}, \dots, p_{t,N}) \in \Delta^N$,
\[
p_t = \frac{\widehat p_t}{\norm{\widehat p_t}_1} \; .
\]
If $\norm{\widehat p_t}_1 = 0$, the algorithm predicts the prior, $\pi$.
Then, the algorithm receives the loss vector
$\ell_t = (\ell_{t,1}, \ell_{t,2}, \dots, \ell_{t,N}) \in [0,1]^N$. Finally, it
feeds the reward to each copy of $A$. The reward for $i$-th copy is $g_{t,i} \in
[-1,1]$ defined as
\begin{align}
\label{eq:gradients_experts_reduction}
g_{t,i} =
\begin{cases}
\langle \ell_t, p_t \rangle - \ell_{t,i} & \text{if } w_{t,i} > 0 \; , \\
\left[\langle \ell_t, p_t \rangle - \ell_{t,i} \right]_+ & \text{if } w_{t,i} \le 0 \; .
\end{cases}
\end{align}

Suppose that the algorithm $A$, for any sequence
$\{g_t\}_{t=1}^\infty$ such that $g_t \in [-1,1]$, satisfies
\begin{equation}
\label{equation:experts-one-dimensional-assumption}
\Wealth_t = 1 + \sum_{i=1}^t g_i w_i \ge F_t\left(\sum_{i=1}^t g_i\right) \; .
\end{equation}
where $\{F_t\}_{t=0}^\infty$ is a sequence of coin-betting potentials for
initial endowment $1$.\footnote{Any initial endowment $\epsilon > 0$ can be
rescaled to $1$. Instead of $F_t(x)$ we would use $F_t(x)/\epsilon$. The
prediction $w_t$ would become $w_t/\epsilon$. The key observation is that $p_t$
is invariant to scaling of $w_t$, hence the resulting LEA algorithm would be the
same regardless of $\epsilon$.}

We show how to convert \eqref{equation:experts-one-dimensional-assumption} into
a regret bound for the LEA algorithm, the proof is in Appendix~\ref{sec:appendix-erpert-reduction}. The regret bound is expressed in terms of
the inverse of $f_t(x) = \ln(F_t(x))$. We define it as follows. We restrict the
function $f_t$ to the domain $I_t \cap [0, \infty)$. By the definition of
coin-betting potential, $f_t$ is convex, strictly increasing. The image of $f_t$
contains $[0,\infty)$, because $F_t(0) \le 1$ and because $F_t$ satisfies
\eqref{equation:potential-limit-assumption}. We define $f_t^{-1}$ as the inverse
of $f_t$. Note that $f_t^{-1}$ is strictly increasing, concave, and its domain
contains $[0, \infty)$.

\begin{theorem}[Regret Bound for Experts]
\label{theorem:regret-bound-experts}
Let $\{F_t\}_{t=0}^\infty$ be a sequence of coin-betting potentials for initial
endowment $1$. Let $f_t^{-1}$ be in the inverse of $f_t(x) = \ln(F_t(x))$.
Let $A$ be an algorithm for OLO over one-dimensional Hilbert space
$\R$. Suppose that $A$ satisfies
\eqref{equation:experts-one-dimensional-assumption} for any sequence
$\{g_t\}_{t=1}^\infty$ such that $g_t \in [-1,1]$. Then, the regret of the
LEA algorithm with prior $\pi \in \Delta_N$, based on $A$, satisfies
\[
\forall u \in \Delta_N \qquad \qquad
\Regret_t(u) \le f_t^{-1}\left( \KL{u}{\pi} \right) \; .
\]
\end{theorem}

