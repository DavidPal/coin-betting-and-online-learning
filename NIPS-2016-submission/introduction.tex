\section{Introduction}
\label{section:introduction}

\vspace{-0.2cm}

We consider the \ac{OLO}~\cite{Cesa-Bianchi-Lugosi-2006, Shalev-Shwartz-2011}
setting. In each round $t$, an algorithm chooses a point $w_t$ from a convex
\emph{decision set} $K$ and then receives a reward vector $g_t$. Algorithm's
goal is to keep its \emph{regret} small, defined as the difference between its
cumulative reward and the cumulative reward of a fixed strategy $u \in K$, that
is
\vspace{-.1cm}
\[
\Regret_T(u) = \sum_{t=1}^T \langle g_t, u \rangle - \sum_{t=1}^T \langle g_t, w_t \rangle \; .
\]
We focus on two particular sets, the $N$-dimensional probability simplex
$\Delta_N = \{ x \in \R^N ~:~ x \ge 0, \norm{x}_1 = 1\}$ and the Hilbert space
$\H$.  \ac{OLO} over $\Delta_N$ is referred to as the problem of \ac{LEA}.  We
assume bounds on the norms of the reward vectors: For \ac{OLO} over $\H$, we
assume that $\norm{g_t} \le 1$, and for \ac{LEA} we assume that $g_t \in
[0,1]^N$.

\ac{OLO} is a basic building block of many machine learning problems. For
example, \ac{OCO}, the problem analogous to \ac{OLO} where $\langle g_t, u
\rangle$ is generalized to $\ell_t(u)$ with $\ell_t$ an arbitrary convex
function, is solved through a reduction to \ac{OLO}~\cite{Shalev-Shwartz-2011}.
\ac{LEA}~\cite{Littlestone-Warmuth-1994, Vovk-1998,
Cesa-Bianchi-Freund-Haussler-Helmbold-Schapire-Warmuth-1997} provides a way of
combining classifiers and it is at the heart of
boosting~\cite{Freund-Schapire-1997}. Batch and stochastic convex optimization
can also be solved through a reduction to \ac{OLO}~\cite{Shalev-Shwartz-2011}.
%Statistical learning with convex losses can also seen as stochastic convex
%optimization and solved through \ac{OCO}~\cite{Munro-1951}, that in turns can
%be reduced to \ac{OLO}.

However, to achieve optimal regret, most of the online algorithms still require
to set hyperparameters, usually learning rates.  For example, to obtain the
optimal bound in \ac{OGD}, the learning rate has to be set with the knowledge
of the norm of the competitor $u$; first entry in Table~\ref{table:bounds}.
Likewise, in Hedge the optimal learning rate depends on the KL divergence
between the prior weighting $\pi$ and the unknown competitor $u$, fourth entry
in Table~\ref{table:bounds}.  Recently, a new family of parameter-free
algorithms that has been proposed, both for
\ac{LEA}~\cite{Chaudhuri-Freund-Hsu-2009, Chernov-Vovk-2010, Luo-Schapire-2014,
Luo-Schapire-2015, Koolen-van-Erven-2015, Foster-Rakhlin-Sridharan-2015} and
for \ac{OLO}/\ac{OCO} over Hilbert spaces~\cite{Streeter-McMahan-2012,
Orabona-2013, McMahan-Abernethy-2013, McMahan-Orabona-2014, Orabona-2014}.
These algorithms adapt to the number of experts and to the norm of the optimal
predictor, respectively, without the need to tune parameters. However, their
\emph{design and underlying intuition} is still a challenge.
%Given the connections
%between \ac{OLO}/\ac{LEA} and machine learning, these algorithms allow to
%design parameter-free batch machine learning algorithms through straightforward
%reductions~\cite{Orabona-2014, Luo-Schapire-2015}.
Also, all existing algorithms for LEA either have sub-optimal regret bound
(e.g. extra $\scO(\log \log T)$ factor) or sub-optimal running time (e.g.
requiring solving a numerical problem in every round, or with extra factors);
see Table~\ref{table:bounds}.

\begin{table}
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{l c c c c}
\toprule
Algorithm & Worst-case regret guarantee& \begin{tabular}{@{}c@{}}Per-Round Time\\Complexity\end{tabular} & Adaptive & \begin{tabular}{@{}c@{}}Unified \\  design\end{tabular}\\
\midrule
\cite{Abernethy-Bartlett-Rakhlin-Tewari-2008} & \begin{tabular}{@{}c@{}}$U \sqrt{T}$ for any $u \in \H$ s.t. $\norm{u} \le U$\\
$\scO(T)$ otherwise\end{tabular} & $\scO(1)$ &  \\
OGD, $\eta=\tfrac{1}{\sqrt{T}}$ \cite{Shalev-Shwartz-2011} & $\scO((1 + \norm{u}^2)\sqrt{T})$, $\forall u \in \H$ & $\scO(1)$ &  \\
\cite{McMahan-Orabona-2014} & $\scO(\norm{u}\sqrt{T \ln(1+\norm{u}T)})$, $\forall u \in \H$ & $\scO(1)$ & \checkmark \\
This paper, Sec.~\ref{section:kt-olo} & $\scO(\norm{u}\sqrt{T \ln(1+\norm{u}T)})$, $\forall u \in \H$ & $\scO(1)$ & \checkmark & \checkmark\\
\midrule
Hedge~\cite{Freund-Schapire-1997}, $\eta=\sqrt{\tfrac{U}{T}}$ & $\scO\left(\sqrt{T U}\right)$ for any $u \in \Delta_N$ s.t. $\KL{u}{\pi} \le U$ & $\scO(N)$ &  \\
\cite{Chaudhuri-Freund-Hsu-2009}  & $\scO\left(\sqrt{T \KL{u}{\pi}}+\ln^2 N\right)$, $\forall u \in \Delta_N$ & $\scO(N\,K)$\footnotemark[1]& \checkmark \\
\cite{Chernov-Vovk-2010} & $\scO\left(\sqrt{T \left(1+\KL{u}{\pi}\right)}\right)$, $\forall u \in \Delta_N$ & $\scO(N\,K)$\footnotemark[1] & \checkmark \\
\cite{Chernov-Vovk-2010, Luo-Schapire-2015,Koolen-van-Erven-2015}\footnotemark[2] & $\scO\left(\sqrt{T \left(\ln \ln T+\KL{u}{\pi}\right)}\right)$, $\forall u \in \Delta_N$ & $\scO(N)$ & \checkmark \\
\cite{Foster-Rakhlin-Sridharan-2015} & $\scO\left(\sqrt{T \left(1+\KL{u}{\pi}\right)}\right)$, $\forall u \in \Delta_N$ & $\scO(N \max_{i} \ln \ln \frac{1}{\pi_i})$\footnotemark[3] & \checkmark & \checkmark \\
This paper, Sec.~\ref{section:kt-lea} & $\scO\left(\sqrt{T \left(1+\KL{u}{\pi}\right)}\right)$, $\forall u \in \Delta_N$ & $\scO(N)$ & \checkmark & \checkmark\\
\bottomrule
\end{tabular}}
\caption{\footnotesize{Algorithms for \ac{OLO} over Hilbert space and \ac{LEA}. We apologize for the big, but necessary, number of symbols used.
All of them are defined in Setion~\ref{section:preliminaries}, while $\eta$ is the learning rate.}}
\label{table:bounds}
\end{table}
\footnotetext[1]{These algorithms require to solve a numerical problem at each step. The number $K$ is the number of steps needed to reach the required precision. Neither the precision nor $K$ are calculated in these papers.
%In general, $K$ is a function of the number rounds $T$ and the number of experts $N$.
}
\footnotetext[2]{The proof in \cite{Koolen-van-Erven-2015} can be modified to prove a KL bound, see \url{http://blog.wouterkoolen.info}.}
\footnotetext[3]{A slightly modified version of algorithm in \cite{Foster-Rakhlin-Sridharan-2015} can be implemented with the stated time complexity~\cite{Foster:private}.}


\textbf{Contributions.} We show that a more fundamental notion subsumes
\emph{both} \ac{OLO} and \ac{LEA} parameter-free algorithms. We show that the
ability to maximize the wealth in bets on the outcomes of coin flips
\emph{implies} \ac{OLO} and \ac{LEA} parameter-free algorithms. We develop a
novel potential-based framework for betting algorithms and we instantiate it
with the Krichevsky-Trofimov estimator.  The resulting algorithms for \ac{OLO}
and \ac{LEA} are new, simple, and natural.  They also have optimal worst-case
guarantees on regret and time complexity; see Table~\ref{table:bounds}.
