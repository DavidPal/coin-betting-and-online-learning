\section{From Coin Betting to OLO over Hilbert Space}
\label{section:reduction_hilbert}

We show how to use a sequence of coin-betting potentials $\{F_t\}_{t=0}^\infty$
to construct an algorithm for \ac{OLO} over a Hilbert space
and how to prove regret bound for it. The basic idea is to realize that
regret minimization is equivalent to wealth maximization over one-dimensional Hilbert space $\R$.
This idea is then generalized to an arbitrary Hilbert space $\H$.

\subsection{A Warm-Up: One-Dimensional Hilbert Space}
\label{section:one-dimensional-hilbert-space-olo}

Let us consider an algorithm for OLO over one-dimensional Hilbert space $\R$.
Let $\{w_t\}_{t=1}^\infty$ be its sequence of predictions on a sequence of
rewards $\{g_t\}_{t=1}^\infty$, $g_t \in [-1,1]$. The total reward of the
algorithm after $t$ rounds is
\[
\Reward_t = \sum_{i=1}^t g_i w_i \; .
\]
Let us define ``wealth'' of the OLO algorithm as $\Wealth_t = \epsilon +
\Reward_t$ in accordance with equation
\eqref{equation:reward-wealth}. Now, suppose we want to satisfy the recurrence
\eqref{equation:wealth-recurrence}. Clearly, the recurrence is not necessarily
satisfied for an arbitrary OLO algorithm. However, if we assume that its
predictions are of the form \begin{equation}
\label{equation:one-dimensional-olo}
w_t = \beta_t \Wealth_{t-1}
= \beta_t \left(\epsilon+ \sum_{i=1}^{t-1} g_i w_i \right),
\end{equation}
where $\beta_t \in [-1,1]$, we see that the recurrence
\eqref{equation:wealth-recurrence} holds. Indeed,
\[
\Wealth_t
= g_t w_t + \Wealth_{t-1}
= \beta_t \Wealth_{t-1} + \Wealth_{t-1}
= (1+\beta_t) \Wealth_{t-1} \; .
\]
This of course works in reverse: If we have a coin-betting algorithm that on a
sequence of coin flips $\{g_t\}_{t=1}^\infty$, $g_t \in [-1,1]$, bets fractions
$\beta_t \in [-1,1]$, we can use it to construct an OLO algorithm in a
one-dimensional Hilbert space $\R$ according to equation
\eqref{equation:one-dimensional-olo}.

If the betting algorithm is based on a sequence of coin-betting potentials
$\{F_t\}_{t=1}^\infty$ then using \eqref{equation:wealth-lower-bound-generic},
\begin{equation}
\label{equation:one-dimensional-olo-reward-lower-bound}
\Reward_T
= \sum_{t=1}^T g_t w_t
= \Wealth_T \ - \ \epsilon \ge F_T\left(\sum_{t=1}^T g_t \right) \ - \ \epsilon \; .
\end{equation}
It is straightforward to convert a lower bound on the reward to an upper bound
on the regret. This can be done using the following lemma, as observed
by~\cite{McMahanO14}.
\begin{lemma}[Reward-Regret relationship]
\label{lemma:reward-regret}
Let $V,V^*$ be a pair of dual vector spaces. Let $F:V \to \R \cup \{+\infty\}$
be a proper convex lower semi-continuous function and let $F^*:V^* \to \R \cup
\{+\infty\}$ be its Fenchel conjugate. Let $w_1, w_2, \dots, w_T \in V$ and
$g_1, g_2, \dots, g_T \in V^*$ be two sequences of vectors.  Then,
\[
\underbrace{\sum_{t=1}^T \langle g_t, w_t \rangle}_{\Reward_T} \ge F\left( \sum_{t=1}^T g_t \right)
\qquad \text{is equivalent to} \qquad
\forall u \in V^*, \quad
\underbrace{\sum_{t=1}^T \langle g_t, u - w_t\rangle}_{\Regret_T(u)} \le F^*(u) \; .
\]
\end{lemma}

Applying the lemma to the function $F(x) = F_T(x) - \epsilon$, we get a regret
upper bound
\[
\forall u \in \H \qquad \qquad
\Regret_T(u) \le F_T^*(u) \ + \ \epsilon \; .
\]

\subsection{Arbitrary Hilbert Space}

The one-dimensional construction for OLO can be generalized to an arbitrary
Hilbert space $\H$. Reward and wealth are defined analogously
to the one-dimensional case:
\begin{align*}
\Reward_t &= \sum_{i=1}^t \langle g_i, w_i \rangle &
& \text{and} &
\Wealth_t &= \epsilon + \Reward_t \; .
\end{align*}
Given a sequence of coin-betting potentials $\{F_t\}_{t=0}^\infty$,
we define fraction
\begin{equation}
\label{equation:potential-based-strategy-hilbert-space}
\beta_t = \tfrac{F_t \left(\norm{\sum_{i=1}^{t-1} g_i} + 1\right) - F_t\left(\norm{\sum_{i=1}^{t-1} g_i} - 1 \right)}{F_t\left(\norm{\sum_{i=1}^{t-1} g_i} + 1 \right) + F_t\left(\norm{\sum_{i=1}^{t-1} g_i} - 1 \right)} \; .
\end{equation}
This definition of $\beta_t$ is a generalization of equation
\eqref{equation:potential-based-strategy}.  Analogously to equation
\eqref{equation:one-dimensional-olo}, the prediction of the OLO algorithm
defined by this potentials is
\begin{equation}
\label{equation:hilbert-space-olo}
w_t = \beta_t \Wealth_{t-1} \frac{\sum_{i=1}^{t-1} g_i}{\norm{\sum_{i=1}^{t-1} g_i}}
= \beta_t \frac{\sum_{i=1}^{t-1} g_i}{\norm{\sum_{i=1}^{t-1} g_i}} \left(\epsilon+ \sum_{i=1}^{t-1} \langle g_i, w_i\rangle \right) \; .
\end{equation}
The only difference between \eqref{equation:hilbert-space-olo} and
\eqref{equation:one-dimensional-olo} is the multiplication by the unit vector
$\frac{\sum_{i=1}^{t-1} g_i}{\norm{\sum_{i=1}^{t-1} g_i}}$. If $\sum_{i=1}^{t-1}
g_i$ is the zero vector, we define $w_t$ be the zero vector as well.
For this prediction strategy we can prove the following regret guarantee.
%
\begin{theorem}[Regret Bound for OLO in Hilbert Spaces]
\label{theorem:hilbert-space-olo-regret-bound}
Let $\{F_t\}_{t=0}^\infty$ be a sequence of excellent coin-betting potentials.
Let $\{g_t\}_{t=1}^\infty$ be any sequence of reward vectors in a Hilbert space
$\H$ such that $\norm{g_t} \le 1$ for all $t$. Then, the algorithm that makes
prediction $w_t$ defined by \eqref{equation:hilbert-space-olo} and
\eqref{equation:potential-based-strategy-hilbert-space} satisfies
\[
\forall u \in \H \qquad \qquad
\Regret_T(u) \le F_T^*\left(\norm{u} \right) \ + \ \epsilon \; .
\]
\end{theorem}

